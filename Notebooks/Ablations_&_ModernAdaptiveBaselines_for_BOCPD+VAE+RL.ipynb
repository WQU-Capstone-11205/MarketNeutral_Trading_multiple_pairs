{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH6xGG-3jMCE"
      },
      "source": [
        "**Note:**\n",
        "\n",
        "It's a good practise to \"restart the session\", whenever changes are made to the github repository\n",
        "\n",
        "\n",
        "##**Step 1:** GitHub setup\n",
        "\n",
        "1) Clone/Update the projects github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0O3SqYdjJyo",
        "outputId": "b0a1f362-0408-47cc-eceb-62dbd0187c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MarketNeutral_Trading_multiple_pairs'...\n",
            "remote: Enumerating objects: 293, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 293 (delta 56), reused 21 (delta 21), pack-reused 208 (from 1)\u001b[K\n",
            "Receiving objects: 100% (293/293), 1.74 MiB | 13.72 MiB/s, done.\n",
            "Resolving deltas: 100% (141/141), done.\n",
            "/content/MarketNeutral_Trading_multiple_pairs\n"
          ]
        }
      ],
      "source": [
        "# Use for the first time to clone the github repo or when the repo is updated\n",
        "%rm -rf /content/MarketNeutral_Trading_multiple_pairs/\n",
        "%cd /content\n",
        "!git clone https://github.com/WQU-Capstone-11205/MarketNeutral_Trading_multiple_pairs.git\n",
        "%cd /content/MarketNeutral_Trading_multiple_pairs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHljENPXl2H3"
      },
      "source": [
        "2) Add the project's github repository's path to the system path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1a2RJ5mSdBO6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "sys.path.append('/content/MarketNeutral_Trading_multiple_pairs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v5tFzh5mGWT"
      },
      "source": [
        "3) Install projects required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nIVlpgfhTTT",
        "outputId": "35d28e95-8639-4cdc-941e-a4813bf441bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.10.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.67.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 4)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (26.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcyeA1YE7564"
      },
      "source": [
        "##**Step 2:** Data loading\n",
        "\n",
        "- Load data and convert to distance spread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP7-iJRn7565",
        "outputId": "eb51cfb0-b6f4-4bf2-aae9-be77ccdaa7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching SP500 pairs from Wikipedia...\n",
            "Calculating spread...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  74 of 74 completed\n",
            "[*********************100%***********************]  74 of 74 completed\n"
          ]
        }
      ],
      "source": [
        "from util.ff_benchmark import get_ff_benchmark_returns\n",
        "from data_loading.fetch_data import fetch_from_yfinance\n",
        "from data_loading.PairsSpread import SP500PairSpread\n",
        "\n",
        "start_date = '2015-01-01' #'2019-01-01' # '2005-01-01'\n",
        "end_date = '2025-01-01' # '2024-01-01' # '2025-01-01'\n",
        "in_sample_cutoff_date = '2022-01-01' # '2017-01-01' # After this date the cointegration fails\n",
        "\n",
        "selector = SP500PairSpread(\n",
        "    selection_start=start_date,\n",
        "    selection_end=end_date,\n",
        "    method=\"distance\",\n",
        "    pairs_per_sector=4\n",
        ")\n",
        "\n",
        "spread = selector.distance_spread()\n",
        "\n",
        "# price data used to compute cointegration\n",
        "tickers = sorted(set(t for pair in spread.columns for t in pair.split(\"-\")))\n",
        "price_df = fetch_from_yfinance(tickers, start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4iKMh2vGj03"
      },
      "source": [
        "**Pair characteristics:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uYf3SVK0GkQL"
      },
      "outputs": [],
      "source": [
        "from util.seed_random import seed_random\n",
        "\n",
        "seed_random(42, device=\"cpu\")\n",
        "\n",
        "train_spread = spread.loc[:in_sample_cutoff_date]\n",
        "test_spread = spread.loc[in_sample_cutoff_date:]\n",
        "\n",
        "spread_returns = spread.pct_change().dropna()\n",
        "train_spread_returns = spread_returns.loc[:in_sample_cutoff_date]\n",
        "test_spread_returns = spread_returns.loc[in_sample_cutoff_date:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTgPGBBMbH5"
      },
      "source": [
        "Run Ablations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvQ0MjiMMbqd",
        "outputId": "22992e17-5ff1-4a72-b592-30de8f7a2dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running RL_only\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 0.681 | Cumulative PnL = 696.169\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.148)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.143 | Cumulative PnL = 557.493\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 3.981 | Cumulative PnL = 301.347\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 5.867 | Cumulative PnL = 714.867\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 7.039 | Cumulative PnL = 715.222\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 7.160 | Cumulative PnL = 715.256\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.054\n",
            "\n",
            "Running RL_BOCPD\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 0.580 | Cumulative PnL = 694.158\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.135)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.212 | Cumulative PnL = 711.427\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.518 | Cumulative PnL = 712.969\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.791 | Cumulative PnL = 713.330\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.907 | Cumulative PnL = 713.440\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.933 | Cumulative PnL = 713.397\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.055\n",
            "\n",
            "Running RL_VAE\n",
            "Epoch 000 | recon loss = 0.849 | kl loss = 0.007 | policy loss = 0.682 | Cumulative PnL = 697.982\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.143)\n",
            "Epoch 001 | recon loss = 0.177 | kl loss = 0.013 | policy loss = 2.172 | Cumulative PnL = 533.426\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.010 | kl loss = 0.019 | policy loss = 4.138 | Cumulative PnL = 436.160\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.010 | kl loss = 0.019 | policy loss = 6.682 | Cumulative PnL = 714.669\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.009 | kl loss = 0.019 | policy loss = 8.665 | Cumulative PnL = 435.509\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.009 | kl loss = 0.019 | policy loss = 9.146 | Cumulative PnL = 670.600\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.054\n",
            "\n",
            "Running FULL\n",
            "Epoch 000 | recon loss = 0.881 | kl loss = 0.007 | policy loss = 0.603 | Cumulative PnL = 696.201\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.127)\n",
            "Epoch 001 | recon loss = 0.210 | kl loss = 0.013 | policy loss = 1.225 | Cumulative PnL = 711.995\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.028 | kl loss = 0.019 | policy loss = 1.514 | Cumulative PnL = 713.098\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.028 | kl loss = 0.019 | policy loss = 1.761 | Cumulative PnL = 713.289\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.028 | kl loss = 0.019 | policy loss = 1.859 | Cumulative PnL = 713.083\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.027 | kl loss = 0.019 | policy loss = 1.894 | Cumulative PnL = 712.765\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.054\n"
          ]
        }
      ],
      "source": [
        "from train.train_loop_rl import train_loop_rl\n",
        "from backtest.evaluate_loop_rl import evaluate_loop_rl\n",
        "\n",
        "bocpd_params = {'hazard': 100, 'mu': 2, 'kappa': 10.0, 'alpha': 10.0, 'beta': 0.8}\n",
        "vae_params = {'input_dim': 2, 'latent_dim': 12, 'hidden_dim': 64, 'lr': 0.0001, 'vae_seq_len': 1, 'kl_wt': 0.0005}\n",
        "rl_params = {'state_dim': 12, 'action_dim': 1, 'hidden_dim': 128, 'actor_l2': 0.0001, 'lr': 5e-06, 'gamma': 0.95, 'action_l2': 0.001, 'cp_weight': 0.15, 'var_penalty': 1e-05, 'var_window': 5, 'dd_penalty': 0.5, 'dd_threshold': 0.5, 'actor_lr': 0.001, 'tau': 0.001}\n",
        "joint_params = {'state_window': 25, 'base_action_sigma': 0.01, 'wt_multplier': 1.8, 'buffer_size_updates': 256, 'sample_batch_size': 128, 'transaction_cost': 0.001, 'tc_scale': 0.8, 'exploration_alpha': 2.0, 'update_every': 10}\n",
        "\n",
        "\n",
        "configs = {\n",
        "    \"RL_only\": dict(use_bocpd=False, use_vae=False),\n",
        "    \"RL_BOCPD\": dict(use_bocpd=True, use_vae=False),\n",
        "    \"RL_VAE\": dict(use_bocpd=False, use_vae=True),\n",
        "    \"FULL\": dict(use_bocpd=True, use_vae=True)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, cfg in configs.items():\n",
        "    print(f\"\\nRunning {name}\")\n",
        "\n",
        "    train_loop_rl(\n",
        "        train_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        save_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    metrics, _ = evaluate_loop_rl(\n",
        "        test_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        load_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    results[name] = metrics[\"sharpe_ratio\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_YuilMYPMyu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb01e826-3b58-4121-8e22-9a4b386639ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of Ablations of Hybrid model:\n",
            "RL_only: 0.05415\n",
            "RL_BOCPD: 0.05459\n",
            "RL_VAE: 0.05401\n",
            "FULL: 0.05446\n"
          ]
        }
      ],
      "source": [
        "print(\"Results of Ablations of Hybrid model:\")\n",
        "for res in results:\n",
        "  print(f\"{res}: {round(results[res],5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from train.train_loop_rl import train_loop_rl\n",
        "from backtest.evaluate_loop_rl import evaluate_loop_rl\n",
        "\n",
        "bocpd_params = {'hazard': 100, 'mu': 2, 'kappa': 10.0, 'alpha': 10.0, 'beta': 0.8}\n",
        "vae_params = {'input_dim': 2, 'latent_dim': 12, 'hidden_dim': 64, 'lr': 0.001, 'vae_seq_len': 1, 'kl_wt': 0.0005}\n",
        "rl_params = {'state_dim': 12, 'action_dim': 1, 'hidden_dim': 128, 'actor_l2': 0.0001, 'lr': 1e-04, 'gamma': 0.95, 'action_l2': 0.001, 'cp_weight': 0.15, 'var_penalty': 1e-05, 'var_window': 5, 'dd_penalty': 0.5, 'dd_threshold': 0.5, 'actor_lr': 0.001, 'tau': 0.001}\n",
        "joint_params = {'state_window': 25, 'base_action_sigma': 0.01, 'wt_multplier': 1.8, 'buffer_size_updates': 256, 'sample_batch_size': 128, 'transaction_cost': 0.001, 'tc_scale': 0.8, 'exploration_alpha': 2.0, 'update_every': 10}\n",
        "\n",
        "\n",
        "configs = {\n",
        "    \"RL_only\": dict(use_bocpd=False, use_vae=False),\n",
        "    \"RL_BOCPD\": dict(use_bocpd=True, use_vae=False),\n",
        "    \"RL_VAE\": dict(use_bocpd=False, use_vae=True),\n",
        "    \"FULL\": dict(use_bocpd=True, use_vae=True)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, cfg in configs.items():\n",
        "    print(f\"\\nRunning {name}\")\n",
        "\n",
        "    train_loop_rl(\n",
        "        train_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        save_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    metrics, _ = evaluate_loop_rl(\n",
        "        test_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        load_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    results[name] = metrics[\"sharpe_ratio\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC3aIoilqZoN",
        "outputId": "1455782f-3578-4d01-ec10-74fca69343a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running RL_only\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.799 | Cumulative PnL = 373.112\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-1.580)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 10.030 | Cumulative PnL = 959.541\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 001 (Sharpe=0.572)\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 12.737 | Cumulative PnL = 715.473\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 12.615 | Cumulative PnL = 715.449\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 11.917 | Cumulative PnL = 715.439\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 11.412 | Cumulative PnL = 715.440\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 006 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 10.797 | Cumulative PnL = 715.442\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 6\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.055\n",
            "\n",
            "Running RL_BOCPD\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.328 | Cumulative PnL = 708.779\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.081)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.915 | Cumulative PnL = 714.302\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.220 | Cumulative PnL = 714.369\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.407 | Cumulative PnL = 714.370\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.486 | Cumulative PnL = 718.878\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.743 | Cumulative PnL = 855.503\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.054\n",
            "\n",
            "Running RL_VAE\n",
            "Epoch 000 | recon loss = 0.144 | kl loss = 0.028 | policy loss = 2.615 | Cumulative PnL = 567.224\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-0.716)\n",
            "Epoch 001 | recon loss = 0.001 | kl loss = 0.020 | policy loss = 8.490 | Cumulative PnL = 777.855\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 14.824 | Cumulative PnL = 950.116\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 002 (Sharpe=-0.437)\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 21.395 | Cumulative PnL = 959.796\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 003 (Sharpe=0.549)\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 22.574 | Cumulative PnL = 1241.911\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 004 (Sharpe=0.826)\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 20.095 | Cumulative PnL = 1171.542\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 006 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 18.381 | Cumulative PnL = 1301.321\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 006 (Sharpe=1.129)\n",
            "Epoch 007 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 15.984 | Cumulative PnL = 1144.641\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 008 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 14.424 | Cumulative PnL = 1264.936\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 009 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 13.331 | Cumulative PnL = 1139.751\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 010 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 12.736 | Cumulative PnL = 1115.126\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 011 | recon loss = 0.000 | kl loss = 0.020 | policy loss = 12.656 | Cumulative PnL = 1010.067\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 11\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.141\n",
            "\n",
            "Running FULL\n",
            "Epoch 000 | recon loss = 0.184 | kl loss = 0.032 | policy loss = 1.249 | Cumulative PnL = 356.462\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-1.626)\n",
            "Epoch 001 | recon loss = 0.011 | kl loss = 0.024 | policy loss = 11.281 | Cumulative PnL = 726.569\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 001 (Sharpe=-0.029)\n",
            "Epoch 002 | recon loss = 0.011 | kl loss = 0.024 | policy loss = 31.700 | Cumulative PnL = 713.465\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 002 (Sharpe=0.044)\n",
            "Epoch 003 | recon loss = 0.011 | kl loss = 0.024 | policy loss = 41.839 | Cumulative PnL = 741.678\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 004 | recon loss = 0.011 | kl loss = 0.023 | policy loss = 41.830 | Cumulative PnL = 860.789\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 005 | recon loss = 0.011 | kl loss = 0.023 | policy loss = 41.574 | Cumulative PnL = 931.420\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 006 | recon loss = 0.011 | kl loss = 0.023 | policy loss = 45.502 | Cumulative PnL = 1014.733\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 007 | recon loss = 0.011 | kl loss = 0.023 | policy loss = 50.226 | Cumulative PnL = 1049.786\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 7\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results of Ablations of Hybrid model:\")\n",
        "for res in results:\n",
        "  print(f\"{res}: {round(results[res],5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h53IAYeKquNT",
        "outputId": "beb340e7-a2ed-4c03-f98d-c3abcd08c4c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of Ablations of Hybrid model:\n",
            "RL_only: 0.05454\n",
            "RL_BOCPD: 0.05443\n",
            "RL_VAE: 0.14089\n",
            "FULL: 0.04785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from train.train_loop_rl import train_loop_rl\n",
        "from backtest.evaluate_loop_rl import evaluate_loop_rl\n",
        "\n",
        "bocpd_params = {'hazard': 100, 'mu': 2, 'kappa': 10.0, 'alpha': 10.0, 'beta': 0.8}\n",
        "vae_params = {'input_dim': 2, 'latent_dim': 12, 'hidden_dim': 64, 'lr': 0.01, 'vae_seq_len': 1, 'kl_wt': 0.0005}\n",
        "rl_params = {'state_dim': 12, 'action_dim': 1, 'hidden_dim': 128, 'actor_l2': 0.0001, 'lr': 1e-04, 'gamma': 0.95, 'action_l2': 0.001, 'cp_weight': 0.15, 'var_penalty': 1e-05, 'var_window': 5, 'dd_penalty': 0.5, 'dd_threshold': 0.5, 'actor_lr': 0.001, 'tau': 0.001}\n",
        "joint_params = {'state_window': 25, 'base_action_sigma': 0.01, 'wt_multplier': 1.8, 'buffer_size_updates': 256, 'sample_batch_size': 128, 'transaction_cost': 0.001, 'tc_scale': 0.8, 'exploration_alpha': 2.0, 'update_every': 10}\n",
        "\n",
        "\n",
        "configs = {\n",
        "    \"RL_only\": dict(use_bocpd=False, use_vae=False),\n",
        "    \"RL_BOCPD\": dict(use_bocpd=True, use_vae=False),\n",
        "    \"RL_VAE\": dict(use_bocpd=False, use_vae=True),\n",
        "    \"FULL\": dict(use_bocpd=True, use_vae=True)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, cfg in configs.items():\n",
        "    print(f\"\\nRunning {name}\")\n",
        "\n",
        "    train_loop_rl(\n",
        "        train_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        save_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    metrics, _ = evaluate_loop_rl(\n",
        "        test_spread,\n",
        "        bocpd_params,\n",
        "        vae_params,\n",
        "        rl_params,\n",
        "        joint_params,\n",
        "        use_bocpd=cfg[\"use_bocpd\"],\n",
        "        use_vae=cfg[\"use_vae\"],\n",
        "        load_dir=f\"checkpoints_{name}\"\n",
        "    )\n",
        "\n",
        "    results[name] = metrics[\"sharpe_ratio\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f9uJvdWqygj",
        "outputId": "6ba09449-a19e-448f-e46a-41e07985651f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running RL_only\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.807 | Cumulative PnL = 496.368\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-1.347)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 11.118 | Cumulative PnL = 741.275\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 001 (Sharpe=0.160)\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 17.085 | Cumulative PnL = 559.254\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 18.363 | Cumulative PnL = 472.777\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 18.617 | Cumulative PnL = 273.203\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 21.705 | Cumulative PnL = 536.912\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 006 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 27.941 | Cumulative PnL = 1268.776\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 006 (Sharpe=0.540)\n",
            "Epoch 007 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 31.322 | Cumulative PnL = 2369.204\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 007 (Sharpe=2.655)\n",
            "Epoch 008 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 30.109 | Cumulative PnL = 2572.361\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 008 (Sharpe=2.933)\n",
            "Epoch 009 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 26.814 | Cumulative PnL = 2459.626\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 010 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 23.841 | Cumulative PnL = 2636.278\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 011 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 20.471 | Cumulative PnL = 2594.003\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 012 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 18.295 | Cumulative PnL = 2679.629\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 012 (Sharpe=3.002)\n",
            "Epoch 013 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 15.996 | Cumulative PnL = 2644.563\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 014 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 14.252 | Cumulative PnL = 2654.587\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 015 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 12.989 | Cumulative PnL = 2636.289\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 016 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 11.341 | Cumulative PnL = 2640.891\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 017 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 9.028 | Cumulative PnL = 2553.113\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 17\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 3.472\n",
            "\n",
            "Running RL_BOCPD\n",
            "Epoch 000 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.312 | Cumulative PnL = 708.948\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=0.081)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 1.934 | Cumulative PnL = 714.471\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.228 | Cumulative PnL = 714.531\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.411 | Cumulative PnL = 714.533\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.490 | Cumulative PnL = 716.837\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.000 | policy loss = 2.793 | Cumulative PnL = 845.106\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 5\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.055\n",
            "\n",
            "Running RL_VAE\n",
            "Epoch 000 | recon loss = 0.033 | kl loss = 0.062 | policy loss = 2.698 | Cumulative PnL = 581.268\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-1.003)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.042 | policy loss = 10.807 | Cumulative PnL = 858.886\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 001 (Sharpe=-0.623)\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 20.431 | Cumulative PnL = 715.560\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 002 (Sharpe=0.045)\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 22.146 | Cumulative PnL = 715.589\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 003 (Sharpe=0.046)\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 20.830 | Cumulative PnL = 715.593\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 18.690 | Cumulative PnL = 715.598\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 006 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 16.669 | Cumulative PnL = 715.591\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 007 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 15.369 | Cumulative PnL = 715.596\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 008 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 14.445 | Cumulative PnL = 715.601\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 8\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.055\n",
            "\n",
            "Running FULL\n",
            "Epoch 000 | recon loss = 0.049 | kl loss = 0.060 | policy loss = 1.254 | Cumulative PnL = 500.527\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 000 (Sharpe=-0.925)\n",
            "Epoch 001 | recon loss = 0.000 | kl loss = 0.043 | policy loss = 6.432 | Cumulative PnL = 623.673\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 002 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 12.773 | Cumulative PnL = 714.019\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 002 (Sharpe=0.044)\n",
            "Epoch 003 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 15.499 | Cumulative PnL = 714.199\n",
            "Saved all models + optimizers\n",
            "Saved best models at epoch 003 (Sharpe=0.044)\n",
            "Epoch 004 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 16.406 | Cumulative PnL = 714.162\n",
            "No improvement. Early stopping patience counter = 1/5\n",
            "Epoch 005 | recon loss = 0.000 | kl loss = 0.041 | policy loss = 16.481 | Cumulative PnL = 714.234\n",
            "No improvement. Early stopping patience counter = 2/5\n",
            "Epoch 006 | recon loss = 0.000 | kl loss = 0.040 | policy loss = 16.221 | Cumulative PnL = 713.807\n",
            "No improvement. Early stopping patience counter = 3/5\n",
            "Epoch 007 | recon loss = 0.000 | kl loss = 0.040 | policy loss = 16.054 | Cumulative PnL = 713.471\n",
            "No improvement. Early stopping patience counter = 4/5\n",
            "Epoch 008 | recon loss = 0.000 | kl loss = 0.040 | policy loss = 15.681 | Cumulative PnL = 495.525\n",
            "No improvement. Early stopping patience counter = 5/5\n",
            "EARLY STOPPING TRIGGERED at epoch 8\n",
            "Multi-pair RL training stopped early due to no improvement in Sharpe.\n",
            "Loaded models/opts\n",
            "Evaluation loop: Sharpe Ratio = 0.053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Results of Ablations of Hybrid model:\")\n",
        "for res in results:\n",
        "  print(f\"{res}: {round(results[res],5)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45MtZDnchIHL",
        "outputId": "c3880730-18c8-468f-b59c-31009aca0776"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results of Ablations of Hybrid model:\n",
            "RL_only: 3.47164\n",
            "RL_BOCPD: 0.05462\n",
            "RL_VAE: 0.0547\n",
            "FULL: 0.05253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V3ZkoPe8hOkK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}